# Paper

-  **Title**: Efficient Decision Tree Construction on Streaming Data
-  **Authors**: Ruoming Jin, Gagan Agrawal
-  **Keywords**: Decision Trees, Streaming Data
-  **Year**: 2006
-  **Link**: http://www.cs.kent.edu/~jin/Papers/sigkdd03.pdf

# Summary

Streaming data gives large amount of data that needs to be processed in real time. This pose different set of problems as opposed to disk-resident datasets. One, because dataset is usually very large and cannot be stored and re-accessed, a one-pass algorithm is required. Two, analysis need to be fast as there is a real-time constraint: the time to finish up an analysis must be less than the interval between the collection of the next streaming data. To begin to solve this problem, the authors put forth a problem definition, in the form of an assumption, namely: A chunk of the stream data can be treated as a random representative of the entire datasets with an underlying distribution. Reduction in memory requirements were reduced partly by not processing nodes at one level of the tree simultaneously. This was implemented by using two queues: Q and AQ. AQ stands for active queue and it contain nodes that are being actively worked on; while Q (queue) contains tree nodes that are yet to be split and not being processed.  If a data instance is received, a decision is made as to what node it belongs to, and it is set into the appropriate Queue. Another important issue with streaming data decision tree construction is that when if it involves numerical attributes, as opposed to categorical attributes, the memory and computation costs increases largely. To solve this problem, a numerical interval approach is proposed. It works thus: intervals of numerical attributes are generated, and are classified into two classes, intact intervals and pruned intervals. Intact intervals are intervals that are not pruned, while pruned intervals are intervals that are pruned because they are thought to not have a split point. The representation of this numerical intervals aided decision tree efficiency. They also introduced a new sampling method that allowed them to use significantly smaller sample size without impacting accuracy. In summary, they were able to show that the efficiency of decision tree construction can be greatly improved on streaming data.
